AWSTemplateFormatVersion: 2010-09-09
Description: "Create an EMR cluster with optionally spot task instances"

Parameters:
    ## Need these to instantiate the template
    VpcId:
        Type: AWS::EC2::VPC::Id

    Subnet:
        Type: AWS::EC2::Subnet::Id

    KeyPair:
        Type: AWS::EC2::KeyPair::KeyName

    S3ConfigPrefix:
        Type: String

    ## Instance types
    MasterInstanceType:
        Type: String
        Default: m5.xlarge

    CoreInstanceType:
        Type: String
        Default: m5.xlarge

    TaskInstanceType:
        Type: String
        Default: m5.xlarge

    ## Instance counts and bounds
    InitialCoreSize:
        Type: Number
        Default: 2

    MaxCoreSize:
        Type: Number
        Default: 10

    InitialTaskSize:
        Type: Number
        Default: 0

    MaxTaskSize:
        Type: Number
        Default: 10

    ## Software versions
    ReleaseLabel:
        Type: String
        Default: emr-5.27.0

    MinicondaScriptURL:
        Type: String
        Default: "https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh"

    ## Misc parameters
    CoreStorage:
        Type: Number
        Default: 200

    TaskStorage:
        Type: Number
        Default: 200

    RootVolumeSize:
        Type: Number
        Default: 32

    SpotPrice:
        Type: Number
        Default: 0 # set to 0 for on-demand

    ReplicationFactor:
        Type: Number
        Default: -1

    SparkDriverMemory:
        Type: String
        Default: 1g

    SparkExecutorMemory:
        Type: String
        Default: 1g

    SparkMaxResultSize:
        Type: String
        Default: 1g

Conditions:
    WithSpotPrice:
        !Not [!Equals [0, !Ref SpotPrice]]

    DefaultReplication:
        !Equals [-1, !Ref ReplicationFactor]

Resources:
    LogBucket:
        Type: AWS::S3::Bucket
        DeletionPolicy: Retain
        Properties:
            AccessControl: Private

    SecurityGroup:
        Type: AWS::EC2::SecurityGroup
        Properties:
            GroupDescription: "Allow SSH from anywhere"
            VpcId: !Ref VpcId
            SecurityGroupIngress:
                - IpProtocol: tcp
                  FromPort: 22
                  ToPort: 22
                  CidrIp: 0.0.0.0/0

    ServiceRole:
        Type: AWS::IAM::Role
        Properties:
            AssumeRolePolicyDocument:
                Statement:
                    - Effect: Allow
                      Action: sts:AssumeRole
                      Principal:
                          Service:
                              - elasticmapreduce.amazonaws.com
            ManagedPolicyArns:
                - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole

    JobFlowRole:
        Type: AWS::IAM::Role
        Properties:
            AssumeRolePolicyDocument:
                Statement:
                    - Effect: Allow
                      Action: sts:AssumeRole
                      Principal:
                          Service:
                              - ec2.amazonaws.com
            ManagedPolicyArns:
                - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforEC2Role

    AutoscalingRole:
        Type: AWS::IAM::Role
        Properties:
            AssumeRolePolicyDocument:
                Statement:
                    - Effect: Allow
                      Action: sts:AssumeRole
                      Principal:
                          Service:
                              - elasticmapreduce.amazonaws.com
                              - application-autoscaling.amazonaws.com
            ManagedPolicyArns:
                - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole

    InstanceProfile:
        Type: AWS::IAM::InstanceProfile
        Properties:
            Roles:
                - !Ref JobFlowRole

    Cluster:
        Type: AWS::EMR::Cluster
        Properties:
            Name: !Ref "AWS::StackName"
            ReleaseLabel: !Ref ReleaseLabel
            VisibleToAllUsers: true

            BootstrapActions:
                - Name: InstallSystemSoftware
                  ScriptBootstrapAction:
                      Path: !Sub s3://${S3ConfigPrefix}/config/bootstrap/install_system_software/run.sh

                # # Spark dependency management is awful, so we're going to
                # # install miniconda on the worker nodes to get known package
                # # versions etc. A step run after Spark installation tells it
                # # to use the miniconda python.
                # - Name: InstallMiniconda
                #   ScriptBootstrapAction:
                #       Path: !Sub s3://${S3ConfigPrefix}/config/bootstrap/install_miniconda/run.sh
                #       Args:
                #           - !Ref S3ConfigPrefix
                #           - !Ref MinicondaScriptURL

            LogUri: !Sub
                - "s3://${bucket}/emr-logs/"
                - { bucket: !Ref LogBucket }

            Applications:
                - Name: Hadoop
                - Name: Spark
                - Name: Tez
                - Name: Livy
                - Name: Pig
                - Name: Mahout
                - Name: Hue
                - Name: Ganglia
                - Name: Presto
                - Name: Hive
                - Name: JupyterHub

            AutoScalingRole: !Ref AutoscalingRole
            JobFlowRole: !Ref InstanceProfile
            ServiceRole: !Ref ServiceRole

            ScaleDownBehavior: TERMINATE_AT_TASK_COMPLETION

            EbsRootVolumeSize: !Ref RootVolumeSize

            Configurations:
                - Classification: spark
                  ConfigurationProperties:
                      maximizeResourceAllocation: true
                - Classification: spark-defaults
                  ConfigurationProperties:
                      spark.sql.parquet.enableVectorizedReader: false
                      spark.sql.files.ignoreCorruptFiles: true
                      spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: 2
                      spark.task.maxFailures: 20
                      spark.driver.memory: !Ref SparkDriverMemory
                      spark.executor.memory: !Ref SparkExecutorMemory
                      spark.driver.maxResultSize: !Ref SparkMaxResultSize
                - Classification: hdfs-site
                  ConfigurationProperties:
                      dfs.replication: !If [DefaultReplication, !Ref "AWS::NoValue", !Ref ReplicationFactor]
                - Classification: presto-connector-hive
                  ConfigurationProperties:
                      hive.metastore.glue.datacatalog.enabled: true
                - Classification: hive-site
                  ConfigurationProperties:
                      hive.metastore.client.factory.class: com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory
                - Classification: spark-hive-site
                  ConfigurationProperties:
                      hive.metastore.client.factory.class: com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory
                - Classification: yarn-site
                  ConfigurationProperties:
                      yarn.log-aggregation-enable: true
                      yarn.log-aggregation.retain-seconds: -1
                      yarn.nodemanager.remote-app-log-dir: !Sub
                          - "s3://${bucket}/aggregated-logs/"
                          - { bucket: !Ref LogBucket }

            Instances:
                TerminationProtected: false
                Ec2KeyName: !Ref KeyPair
                Ec2SubnetId: !Ref Subnet
                AdditionalMasterSecurityGroups:
                    - !Ref SecurityGroup

                MasterInstanceGroup:
                    InstanceCount: 1
                    InstanceType: !Ref MasterInstanceType
                    Market: ON_DEMAND
                    Name: MasterInstance

                CoreInstanceGroup:
                    InstanceCount: !Ref InitialCoreSize
                    InstanceType: !Ref CoreInstanceType
                    Market: ON_DEMAND
                    Name: CoreInstance

                    EbsConfiguration:
                        EbsBlockDeviceConfigs:
                            - VolumeSpecification:
                                  SizeInGB: !Ref CoreStorage
                                  VolumeType: gp2
                              VolumesPerInstance: 1
                        EbsOptimized: true

                    AutoScalingPolicy:
                        Constraints:
                            MinCapacity: 1
                            MaxCapacity: !Ref MaxCoreSize

                        Rules:
                            - Name: CoreNodeScaleOut
                              Description: "Core node scale-out based on HDFS utilization"
                              Action:
                                  SimpleScalingPolicyConfiguration:
                                      AdjustmentType: CHANGE_IN_CAPACITY
                                      ScalingAdjustment: 1
                                      CoolDown: 300
                              Trigger:
                                  CloudWatchAlarmDefinition:
                                      ComparisonOperator: GREATER_THAN
                                      EvaluationPeriods: 1
                                      MetricName: HDFSUtilization
                                      Namespace: AWS/ElasticMapReduce
                                      Period: 300
                                      Threshold: 80
                                      Statistic: AVERAGE
                                      Unit: PERCENT
                                      Dimensions:
                                          - Key: JobFlowId
                                            Value: "${emr.clusterId}"

    TaskInstanceGroupConfig:
        Type: AWS::EMR::InstanceGroupConfig
        Properties:
            Name: TaskInstance
            InstanceRole: TASK
            JobFlowId: !Ref Cluster
            InstanceCount: !Ref InitialTaskSize
            InstanceType: !Ref TaskInstanceType
            Market: !If [WithSpotPrice, SPOT, ON_DEMAND]
            BidPrice: !If [WithSpotPrice, !Ref SpotPrice, !Ref "AWS::NoValue"]

            EbsConfiguration:
                EbsBlockDeviceConfigs:
                    - VolumeSpecification:
                          SizeInGB: !Ref TaskStorage
                          VolumeType: gp2
                      VolumesPerInstance: 1
                EbsOptimized: true

            Configurations:
                - Classification: spark
                  ConfigurationProperties:
                      maximizeResourceAllocation: true
                - Classification: spark-defaults
                  ConfigurationProperties:
                      spark.sql.parquet.enableVectorizedReader: false
                      spark.sql.files.ignoreCorruptFiles: true
                      spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: 2
                      spark.task.maxFailures: 20
                      spark.driver.memory: !Ref SparkDriverMemory
                      spark.executor.memory: !Ref SparkExecutorMemory
                      spark.driver.maxResultSize: !Ref SparkMaxResultSize
                - Classification: hdfs-site
                  ConfigurationProperties:
                      dfs.replication: !If [DefaultReplication, !Ref "AWS::NoValue", !Ref ReplicationFactor]
                - Classification: presto-connector-hive
                  ConfigurationProperties:
                      hive.metastore.glue.datacatalog.enabled: true
                - Classification: hive-site
                  ConfigurationProperties:
                      hive.metastore.client.factory.class: com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory
                - Classification: spark-hive-site
                  ConfigurationProperties:
                      hive.metastore.client.factory.class: com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory
                - Classification: yarn-site
                  ConfigurationProperties:
                      yarn.log-aggregation-enable: true
                      yarn.log-aggregation.retain-seconds: -1
                      yarn.nodemanager.remote-app-log-dir: !Sub
                          - "s3://${bucket}/aggregated-logs/"
                          - { bucket: !Ref LogBucket }

            AutoScalingPolicy:
                Constraints:
                    MinCapacity: 0
                    MaxCapacity: !Ref MaxTaskSize
                Rules:
                    - Name: TaskNodeScaleOut
                      Description: "Task node scale-out based on memory utilization"
                      Action:
                          SimpleScalingPolicyConfiguration:
                              AdjustmentType: CHANGE_IN_CAPACITY
                              ScalingAdjustment: 1
                              CoolDown: 300
                      Trigger:
                          CloudWatchAlarmDefinition:
                              ComparisonOperator: LESS_THAN
                              EvaluationPeriods: 1
                              MetricName: YARNMemoryAvailablePercentage
                              Namespace: AWS/ElasticMapReduce
                              Period: 300
                              Threshold: 20
                              Statistic: AVERAGE
                              Unit: PERCENT
                              Dimensions:
                                  - Key: JobFlowId
                                    Value: "${emr.clusterId}"

                    - Name: TaskNodeScaleIn
                      Description: "Task node scale-in based on memory utilization"
                      Action:
                          SimpleScalingPolicyConfiguration:
                              AdjustmentType: CHANGE_IN_CAPACITY
                              ScalingAdjustment: -1
                              CoolDown: 300
                      Trigger:
                          CloudWatchAlarmDefinition:
                              ComparisonOperator: GREATER_THAN
                              EvaluationPeriods: 1
                              MetricName: YARNMemoryAvailablePercentage
                              Namespace: AWS/ElasticMapReduce
                              Period: 300
                              Threshold: 75
                              Statistic: AVERAGE
                              Unit: PERCENT
                              Dimensions:
                                  - Key: JobFlowId
                                    Value: "${emr.clusterId}"

    DebugSetupStep:
        Type: AWS::EMR::Step
        Properties:
            Name: SetupDebuggingTool
            ActionOnFailure: CONTINUE
            JobFlowId: !Ref Cluster
            HadoopJarStep:
                Jar: "command-runner.jar"
                Args:
                    - state-pusher-script

#    InstallSpatialStep:
#        Type: AWS::EMR::Step
#        Properties:
#            Name: InstallSpatial
#            ActionOnFailure: CONTINUE
#            JobFlowId: !Ref Cluster
#            HadoopJarStep:
#                Jar: !Sub s3://${AWS::Region}.elasticmapreduce/libs/script-runner/script-runner.jar
#                Args:
#                    - !Sub s3://${S3ConfigPrefix}/config/step/install_spatial/run.sh
#                    - !Ref S3ConfigPrefix
#
#    # Tell Spark to use miniconda rather than the system python
#    SetupMinicondaStep:
#        Type: AWS::EMR::Step
#        Properties:
#            Name: SetupMiniconda
#            ActionOnFailure: CONTINUE
#            JobFlowId: !Ref Cluster
#            HadoopJarStep:
#                Jar: !Sub s3://${AWS::Region}.elasticmapreduce/libs/script-runner/script-runner.jar
#                Args:
#                    - !Sub s3://${S3ConfigPrefix}/config/step/setup_miniconda/run.sh
#                    - !Ref S3ConfigPrefix
#
#    # Get EMR's Docker Jupyterhub configured to use the same conda environment
#    # we've deployed to the nodes and made Spark's default. This way, no
#    # confusing version mismatch errors.
#    SetupJupyterhubStep:
#        Type: AWS::EMR::Step
#        Properties:
#            Name: SetupJupyterhub
#            ActionOnFailure: CONTINUE
#            JobFlowId: !Ref Cluster
#            HadoopJarStep:
#                Jar: !Sub s3://${AWS::Region}.elasticmapreduce/libs/script-runner/script-runner.jar
#                Args:
#                    - !Sub s3://${S3ConfigPrefix}/config/step/setup_jupyterhub/run.sh
#                    - !Ref S3ConfigPrefix

Outputs:
    ClusterDNS:
        Description: EMR Cluster DNS
        Value: !GetAtt Cluster.MasterPublicDNS

    ClusterID:
        Description: EMR Cluster ID
        Value: !Ref Cluster

